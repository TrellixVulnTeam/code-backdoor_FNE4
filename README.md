# Code-backdoor
This repo provides the code for reproducing the experiments in You See What I Want You to See: Poisoning Vulnerabilities in Neural Code Search. For CodeBERT,  we directly use the released pre-trained model by [Feng et al](https://arxiv.org/pdf/2002.08155.pdf). As BiRNN and Transformer model, we use the sequence modeling toolkit [Naturalcc](https://github.com/CGCL-codes/naturalcc). In this text, we focus more on the process of backdoor attack. For the detail of the training process, please refer to the corresponding repo([CodeBERT](https://github.com/microsoft/CodeBERT), [Naturalcc](https://github.com/CGCL-codes/naturalcc)).
# Requirements
- PyTorch version >= 1.6.0
- Python version >= 3.6
- GCC/G++ > 5.0
```shell
pip install -r requirements.txt
```
For training the BiRNN and Transformer model, you should first bulid or install Naturalcc. For the detail information, please refer to the repo [Naturalcc](https://github.com/CGCL-codes/naturalcc).
# Backdoor attack
-BiRNN and Transformer
ss
-CodeBERT
dd
<!--
**code-backdoor/code-backdoor** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
